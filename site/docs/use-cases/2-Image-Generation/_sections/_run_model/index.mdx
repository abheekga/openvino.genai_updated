import CodeExampleCPP from './_code_example_cpp.mdx';
import CodeExamplePython from './_code_example_python.mdx';

## Run Model Using OpenVINO™ GenAI

OpenVINO GenAI introduces `Text2ImagePipeline` for inference of text-to-image models such as Stable Diffusion 1.5, 2.1, XL, LCM, Flux, and more.
See all supported [image generation models](/docs/supported-models/#image-generation-models).

<LanguageTabs>
    <TabItemPython>
        <Tabs groupId="device">
            <TabItem label="CPU" value="cpu">
                <CodeExamplePython device="CPU" />
            </TabItem>
            <TabItem label="GPU" value="gpu">
                <CodeExamplePython device="GPU" />
            </TabItem>
        </Tabs>
    </TabItemPython>
    <TabItemCpp>
        <Tabs groupId="device">
            <TabItem label="CPU" value="cpu">
                :::info

                Code below requires installation of C++ compatible package.
                See [here](https://docs.openvino.ai/2025/get-started/install-openvino/install-openvino-genai.html#archive-installation) for additional setup details,
                or [How to Build OpenVINO™ GenAI APP in C++](https://medium.com/openvino-toolkit/how-to-build-openvino-genai-app-in-c-32dcbe42fa67) blog for full instruction.

                :::
                <CodeExampleCPP device="CPU" />
            </TabItem>
            <TabItem label="GPU" value="gpu">
                <CodeExampleCPP device="GPU" />
            </TabItem>
        </Tabs>
    </TabItemCpp>
</LanguageTabs>

:::tip

Use CPU or GPU as devices without any other code change.

:::

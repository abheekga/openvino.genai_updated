# OpenVINO Latent Consistency Model C++ pipeline
The pure C++ text-to-image pipeline, driven by the OpenVINO native API for SD v1.5 Latent Consistency Model with LCM  Scheduler. It includes advanced features like [OpenVINO extension for tokenizers](https://github.com/openvinotoolkit/openvino_contrib/blob/master/modules/custom_operations/user_ie_extensions/tokenizer/python/README.md). This demo has been tested for Linux platform only.

> [!NOTE]
>This tutorial assumes that the current working directory is `<openvino.genai repo>/image_generation/lcm_dreamshaper_v7/cpp/` and all paths are relative to this folder.
> [!NOTE]
>You can use `set_up_and_run.sh` script for the fast start - it'll convert LCM model to OpenVINO IR formar and run C++ sample.

## Step 1: Prepare build environment

C++ Packages:
* [CMake](https://cmake.org/download/): Cross-platform build tool
* [OpenVINO](https://docs.openvino.ai/2023.2/openvino_docs_install_guides_overview.html): Model inference

## Step 2: Latent Consistency Model and Tokenizer models

### Latent Consistency Model model:

1. Prepare a conda python environment and install dependencies:
    ```shell
    conda create -n LCM-CPP python==3.10
    conda activate LCM-CPP
    python -m pip install -r scripts/requirements.txt
    ```
2. Run model conversion script to download and convert PyTorch model to OpenVINO IR via [optimum-intel](https://github.com/huggingface/optimum-intel). Please, use the script `scripts/convert_model.py` to convert the model:
    ```shell
    cd scripts
    python convert_model.py -lcm "SimianLuo/LCM_Dreamshaper_v7" -t FP16
    ```

> [!NOTE]
>Only static model is currently supported for this sample.

### Tokenizer model

Install OpenVINO tokenizers using the following command:
    ```shell
    python -m pip install ../../../thirdparty/openvino_contrib/modules/custom_operations/[transformers]
    ```

## Step 3: Build the LCM application

```shell
conda activate LCM-CPP
cmake -DCMAKE_BUILD_TYPE=Release -S . -B build
cmake --build build --parallel
```

## Step 4: Run Pipeline
```shell
./lcm_dreamshaper [-p <posPrompt>] [-s <seed>] [--height <output image>] [--width <output image>] [-d <device>] [-r <readNPLatent>] [-a <alpha>] [-h <help>] [-m <modelPath>] [-t <modelType>]

Usage:
  lcm_dreamshaper [OPTION...]
```

* `-p, --posPrompt arg` Initial positive prompt for SD  (default: cyberpunk cityscape like Tokyo New York  with tall buildings at dusk golden hour cinematic lighting)
* `-d, --device arg`    AUTO, CPU, or GPU (default: CPU)
* `--step arg`          Number of diffusion step ( default: 20)
* `-s, --seed arg`      Number of random seed to generate latent (default: 42)
* `--num arg`           Number of image output(default: 1)
* `--height arg`        Height of output image (default: 512)
* `--width arg`         Width of output image (default: 512)
* `-c, --useCache`      Use model caching
* `-r, --readNPLatent`  Read numpy generated latents from file
* `-m, --modelPath arg` Specify path of SD model IR (default: ../scripts/SimianLuo/LCM_Dreamshaper_v7)
* `-t, --type arg`      Specify the type of SD model IR (FP16_static or FP16_dyn) (default: FP16_static)
* `-l, --loraPath arg`  Specify path of lora file. (*.safetensors). (default: )
* `-a, --alpha arg`     alpha for lora (default: 0.75)
* `-h, --help`          Print usage

Example:

Positive prompt: a beautiful pink unicorn

Read the numpy latent input and noise for scheduler instead of C++ std lib for the alignment with Python pipeline.

* Generate image with random data generated by Python `./lcm_dreamshaper -r`

![image](https://github.com/likholat/openvino.genai/pull/4#issuecomment-1867928176)

* Generate image with C++ lib generated latent and noise : `./lcm_dreamshaper`

![image](https://github.com/likholat/openvino.genai/pull/4#issuecomment-1867939235)

## Benchmark:

The performance and image quality of C++ pipeline are aligned with Python

For the generation quality, C++ random generation with MT19937 results is differ from `numpy.random.randn()` and `diffusers.utils.randn_tensor`. Hence, please use `-r, --readNPLatent` for the alignment with Python (this latent file is for output image 512X512 only)
